{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25686c50",
   "metadata": {},
   "source": [
    "# Data Science Blog Notebook - Stack Overflow Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ad151",
   "metadata": {},
   "source": [
    "In this work, I intend to take a closer look on the relation between a developer's profile and his/her income, as well as what characteristics people think could provide them with a better financial response from the market. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ad8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df_d = pd.read_csv('../Data_Science_Post/survey_results_public.csv')\n",
    "df_q = pd.read_csv('../Data_Science_Post/survey_results_schema.csv')\n",
    "df_d.set_index('Respondent',inplace=True)\n",
    "df_q.set_index('Column',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a88f2b",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13998018",
   "metadata": {},
   "source": [
    "Since I ran into an error trying to import a python file with de functions I would use for the analysis, I had to work around it by defining the needed functions on this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9288e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def des_var(ind_var,dep_var):\n",
    "    '''\n",
    "    INPUT:\n",
    "    ind_var - list with dependent variables of interest\n",
    "    dep_var - list with independent variables of interest\n",
    "    \n",
    "    OUTPUT:\n",
    "    new_df - a dataframe of each look_for with the count of how often it shows up\n",
    "    '''\n",
    "    \n",
    "    print('Independent Variables\\n')\n",
    "    for entry in ind_var:\n",
    "        text = df_q.loc[entry]\n",
    "        pd.options.display.max_colwidth = len(text)\n",
    "        print(f'{entry}: {text[0]}')    \n",
    "    print('\\n-----------------------------------------------------\\n')\n",
    "    print('Dependent Variables\\n')\n",
    "    for entry in dep_var:\n",
    "        text = df_q.loc[entry]\n",
    "        pd.options.display.max_colwidth = len(text)\n",
    "        print(f'{entry}: {text[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e63719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=False, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "#     df_non_cat = df[list(set(df.columns)-set(cat_cols))]\n",
    "#     dummies = pd.get_dummies(df[list(cat_cols)], drop_first = True, dummy_na=dummy_na)\n",
    "#     df = pd.concat([df_non_cat,dummies],axis = 1)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb713080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_lm_mod(X, y, cutoffs, test_size=.30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "\n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    for cutoff in cutoffs:\n",
    "        # reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "        # split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # fit the model and obtain pred response\n",
    "        lm_model = LinearRegression(normalize=True)\n",
    "        lm_model.fit(X_train, y_train)\n",
    "        y_test_preds = lm_model.predict(X_test)\n",
    "        y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "        # append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "\n",
    "    best_cutoff = max(results, key=results.get)\n",
    "\n",
    "    # reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    # split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # fit the model\n",
    "    lm_model = LinearRegression(normalize=True)\n",
    "    lm_model.fit(X_train, y_train)\n",
    "\n",
    "    return r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdb5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5f977",
   "metadata": {},
   "source": [
    "### Ideas:\n",
    "\n",
    "1. How well analytical and methodical thinkers do financially as developers?\n",
    "2. Do satisfaction levels relates to the idea of being well paid?\n",
    "3. Do people who value a high level of security in a job feel that way because they are being better paid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621839bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is here just to help me keep track of the variables I would work throughout the assignment.\n",
    "\n",
    "q1_X = ['BoringDetails','ProblemSolving','EnjoyDebugging','RightWrongWay']\n",
    "q1_y = ['Salary']\n",
    "q2_X = ['JobSatisfaction','CareerSatisfaction']\n",
    "q2_y = ['Overpaid']\n",
    "q3_X = ['JobSecurity']\n",
    "q3_y_1 = ['Salary']\n",
    "q3_y_2 = ['Overpaid']\n",
    "\n",
    "des_var(q3_X,q3_y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dafc0c",
   "metadata": {},
   "source": [
    "Target variables used for the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc275f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_var = ['ProblemSolving','BoringDetails','JobSecurity','Overpaid','DifficultCommunication','HighestEducationParents','Country','SeriousWork','RightWrongWay','EnjoyDebugging',] #Independent Variables\n",
    "y_var = ['CareerSatisfaction','JobSatisfaction','Salary',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660825f4",
   "metadata": {},
   "source": [
    "### 1st Question: How well analytical and methodical developers do financially?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "044940bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the base dataframe:\n",
    "q1 = set(q1_X)|set(q1_y)\n",
    "df1 = df_d[q1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c465698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns where all the values are null:\n",
    "df1_no_nan = df1.dropna(axis=0,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "971f5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns where the salary is not provided:\n",
    "sal_no_nan = df1_no_nan.dropna(subset=['Salary'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935908e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most relevant independent variables: \"BoringDetails\" and \"EnjoyDebugging\" (Must be dropped if NaN):\n",
    "rel_var = ['BoringDetails','EnjoyDebugging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9905632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where relevant ind. variables are NaN:\n",
    "data_q1 = sal_no_nan.dropna(subset=rel_var,axis=0,how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of how many NaN entries are in the remaining dependent variables \"ProblemSolving\" and \"RightWrongWay\"\n",
    "print(data_q1['ProblemSolving'].isnull().sum(),data_q1['RightWrongWay'].isnull().sum(),sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbda514",
   "metadata": {},
   "source": [
    "Since the entire database is comprised of 5844 values, I will assume that dropping between 25 to 36 values does not result in a considerable loss in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0c9812e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping NaN values from \"ProblemSolving\" ad \"RightWrongWay\":\n",
    "df_q1 = data_q1.dropna(subset=['ProblemSolving','RightWrongWay'],axis=0,how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2674eb",
   "metadata": {},
   "source": [
    "With that, the database has been cleared of NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fbcb0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dummy columns:\n",
    "df1_dummy = create_dummy_df(df_q1,q1_X,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the dependent and independent input dataframes for the Linear Regression models:\n",
    "X1 = df1_dummy.drop(labels=['Salary'],axis=1)\n",
    "y1 = df1_dummy['Salary']\n",
    "\n",
    "# Obtaining the optimal linear model:\n",
    "cutoffs = [2000, 1500,1250,1000,750,500,250, 100, 50,40,30,20,10,5,0]\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = find_optimal_lm_mod(X1, y1, cutoffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40f0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the best values for Number of Features in order to maximize the R2 value (Check):\n",
    "y_test_preds = lm_model.predict(X_test)\n",
    "y_train_preds = lm_model.predict(X_train)\n",
    "print(r2_score(y_test,y_test_preds),r2_score(y_train,y_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to weight the coefficient's influence:\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "# Showing results:\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388134d5",
   "metadata": {},
   "source": [
    "Looking at the weights of the independent variables of this linear regression, we cannot assume a direct correlation between one's salary and whole of the characteristics described by them.\n",
    "\n",
    "Therefore, in order to obtain some clarification, we shall look at the most notable variables individually: \"Attention to Details\" and the \"Pleasure in Debugging\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97579ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoringDetails:\n",
    "df1_sal_BD = sal_no_nan[['Salary','BoringDetails']]\n",
    "\n",
    "#Filling missing values with the mode:\n",
    "df1_sal_BD['BoringDetails'].fillna(df1_sal_BD['BoringDetails'].mode()[0],inplace=True)\n",
    "df1_BD.groupby('BoringDetails').mean().sort_values('Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe51398",
   "metadata": {},
   "source": [
    "The results show that developers who are not bothered by details tend to earn bigger salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnjoyDebugging:\n",
    "df1_sal_ED = sal_no_nan[['Salary','EnjoyDebugging']]\n",
    "#Filling missing values with the mode\n",
    "df1_sal_ED['EnjoyDebugging'].fillna(df1_sal_ED['EnjoyDebugging'].mode()[0],inplace=True)\n",
    "df1_ED.groupby('EnjoyDebugging').mean().sort_values(by='Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c329378",
   "metadata": {},
   "source": [
    "The tendency to enjoy debugging does not seem to hurt one's salary, although the same cannot be said for people who have a strong deslike for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc59b09",
   "metadata": {},
   "source": [
    "### 2nd Question: Do satisfaction levels relates to the idea of being well paid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f09bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the base dataframe:\n",
    "q2 = set(q2_X)|set(q2_y)\n",
    "df2 = df_d[q2]\n",
    "\n",
    "# Removing rows without information:\n",
    "df2.dropna(how='all',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f744a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN values from the \"Overpaid\" column:\n",
    "df2.dropna(subset=['Overpaid'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the influence of the subcategories of \"Overpaid\" over \"CareerSatisfaction\":\n",
    "df2[['Overpaid','CareerSatisfaction']].groupby('Overpaid').mean().sort_values(by='CareerSatisfaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1c7d6",
   "metadata": {},
   "source": [
    "It seems that there is a direct link between the feeling of being overpaid and the satisfaction one's career brings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the influence of the subcategories of \"Overpaid\" over \"JobSatisfaction\":\n",
    "df2[['Overpaid','JobSatisfaction']].groupby('Overpaid').mean().sort_values(by='JobSatisfaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645494e",
   "metadata": {},
   "source": [
    "The only conclusion we can draw from these results is that the satisfaction one feels doing a job is greatly harmed by the feeling of being underpaid, since the options \"Greatly underpaid\" and \"Somewhat underpaid\" were the ones that returned the lowest values for Job Satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85311a",
   "metadata": {},
   "source": [
    "### 3rd Question: Do people who value a high level of job security feel that way because they are being better paid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0ee948f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the base dataframe:\n",
    "q3_X = ['JobSecurity']\n",
    "q3_y_1 = ['Salary']\n",
    "q3_y_2 = ['Overpaid']\n",
    "\n",
    "q3_1 = set(q3_X)|set(q3_y_1)|set(q3_y_2)\n",
    "df3 = df_d[q3_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555f737",
   "metadata": {},
   "source": [
    "Checking what people define as overpaid x underpaid (explored out of curiosity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN values for both Salary and Overpaid columns:\n",
    "df3_nona_sal_op = df3.dropna(subset=['Salary','Overpaid'],axis=0)\n",
    "\n",
    "# Removing outliers on the set that includes people who think they are \"greatly overpaid\" and that makes less than 12000\n",
    "# dollars per year (1000 USD per month)\n",
    "clean_df = df3_nona_sal_op[df3_nona_sal_op['Overpaid']=='Greatly overpaid'][df3_nona_sal_op['Salary']<12000]\n",
    "drop_list = clean_df.index\n",
    "df3_nona_sal_op.drop(index=drop_list,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our target is Job Security, and this variable is an opinion, we'll remove the NaN values due to the subjectivity\n",
    "# of this variable.\n",
    "df3_final = df3_nona_sal_op.dropna(subset=['JobSecurity'],axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7732bdf",
   "metadata": {},
   "source": [
    "First, we will check the avarage values that define what the subjects in the sample think about their income, that is,\n",
    "the relation between salary and the feeling of being overpaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_final[['Overpaid','Salary']].groupby('Overpaid').mean().sort_values(by='Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a3e9e",
   "metadata": {},
   "source": [
    "Next, we will do the same check for the variables Salary and JobSecurity (also done out of curiosity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_final[['JobSecurity','Salary']].groupby('JobSecurity').mean().sort_values(by='Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9091d19",
   "metadata": {},
   "source": [
    "The salary avarage differences are negligible between the subcategories of in \"JobSecurity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies in order to analyze the weight of \"Overpaid\" on \"JobSecurity\":\n",
    "df3_JS_OP = create_dummy_df(df3_final[['JobSecurity','Overpaid']], ['Overpaid'], dummy_na=False)\n",
    "q3_out = df3_JS_OP.groupby('JobSecurity').sum()\n",
    "\n",
    "# Transforming the sums into percentages of the subsets in \"Overpaid\":\n",
    "col_perc = lambda col:(col/col.sum())*100\n",
    "q3_perc=q3_out.apply(col_perc)\n",
    "\n",
    "# Rearranging the index for easier analysis:\n",
    "set_index = ['Strongly agree','Agree','Somewhat agree','Disagree','Strongly disagree']\n",
    "q3_perc.reindex(set_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60f626",
   "metadata": {},
   "source": [
    "From these results, we can see that the percentages of people who have a determined opinion about Job Security do not vary considerably between subcategories of \"Overpaid\", therefore we can conclude that the feeling of having a safe job is not related to how well one thinks he/she is being paid, but is more linked to the general feeling of the population."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
